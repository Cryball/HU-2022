{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HU 2022 Chistyakov Daniil Task 1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2e9MT_DhSSrn",
        "outputId": "4bd67c70-9000-44e0-cc85-1a2c0f217607"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: mindinsight in /usr/local/lib/python3.7/dist-packages (1.7.0)\n",
            "Requirement already satisfied: yapf>=0.30.0 in /usr/local/lib/python3.7/dist-packages (from mindinsight) (0.32.0)\n",
            "Requirement already satisfied: XlsxWriter>=1.3.2 in /usr/local/lib/python3.7/dist-packages (from mindinsight) (3.0.3)\n",
            "Requirement already satisfied: marshmallow>=3.10.0 in /usr/local/lib/python3.7/dist-packages (from mindinsight) (3.15.0)\n",
            "Requirement already satisfied: numpy>=1.17.0 in /usr/local/lib/python3.7/dist-packages (from mindinsight) (1.21.6)\n",
            "Requirement already satisfied: grpcio>=1.36.1 in /usr/local/lib/python3.7/dist-packages (from mindinsight) (1.44.0)\n",
            "Requirement already satisfied: MarkupSafe>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from mindinsight) (2.0.1)\n",
            "Requirement already satisfied: Werkzeug>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from mindinsight) (1.0.1)\n",
            "Requirement already satisfied: scikit-learn>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from mindinsight) (1.0.2)\n",
            "Requirement already satisfied: psutil>=5.7.0 in /usr/local/lib/python3.7/dist-packages (from mindinsight) (5.9.0)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.7/dist-packages (from mindinsight) (7.1.2)\n",
            "Requirement already satisfied: Flask>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from mindinsight) (1.1.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.8 in /usr/local/lib/python3.7/dist-packages (from mindinsight) (0.2.0)\n",
            "Requirement already satisfied: protobuf>=3.13.0 in /usr/local/lib/python3.7/dist-packages (from mindinsight) (3.17.3)\n",
            "Requirement already satisfied: itsdangerous>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from mindinsight) (1.1.0)\n",
            "Requirement already satisfied: pandas>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from mindinsight) (1.3.5)\n",
            "Requirement already satisfied: scipy>=1.5.2 in /usr/local/lib/python3.7/dist-packages (from mindinsight) (1.7.3)\n",
            "Requirement already satisfied: gunicorn>=20.0.4 in /usr/local/lib/python3.7/dist-packages (from mindinsight) (20.1.0)\n",
            "Requirement already satisfied: treelib>=1.6.1 in /usr/local/lib/python3.7/dist-packages (from mindinsight) (1.6.1)\n",
            "Requirement already satisfied: Jinja2>=2.10.1 in /usr/local/lib/python3.7/dist-packages (from mindinsight) (2.11.3)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.7/dist-packages (from mindinsight) (6.0)\n",
            "Requirement already satisfied: click<8.0,>=5.1 in /usr/local/lib/python3.7/dist-packages (from Flask>=1.1.1->mindinsight) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from google-pasta>=0.1.8->mindinsight) (1.15.0)\n",
            "Requirement already satisfied: setuptools>=3.0 in /usr/local/lib/python3.7/dist-packages (from gunicorn>=20.0.4->mindinsight) (57.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from marshmallow>=3.10.0->mindinsight) (21.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.0.4->mindinsight) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.0.4->mindinsight) (2022.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.23.1->mindinsight) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.23.1->mindinsight) (1.1.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from treelib>=1.6.1->mindinsight) (0.16.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->marshmallow>=3.10.0->mindinsight) (3.0.8)\n"
          ]
        }
      ],
      "source": [
        "! pip install mindinsight"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install mindspore"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QDbeh7BfW0dJ",
        "outputId": "d3387c90-f41e-43d4-833e-dd6dc892190c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: mindspore in /usr/local/lib/python3.7/dist-packages (1.7.0)\n",
            "Requirement already satisfied: protobuf>=3.13.0 in /usr/local/lib/python3.7/dist-packages (from mindspore) (3.17.3)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.7/dist-packages (from mindspore) (7.1.2)\n",
            "Requirement already satisfied: numpy>=1.17.0 in /usr/local/lib/python3.7/dist-packages (from mindspore) (1.21.6)\n",
            "Requirement already satisfied: psutil>=5.6.1 in /usr/local/lib/python3.7/dist-packages (from mindspore) (5.9.0)\n",
            "Requirement already satisfied: asttokens>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from mindspore) (2.0.5)\n",
            "Requirement already satisfied: scipy>=1.5.2 in /usr/local/lib/python3.7/dist-packages (from mindspore) (1.7.3)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from mindspore) (21.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from asttokens>=2.0.0->mindspore) (1.15.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->mindspore) (3.0.8)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import argparse\n",
        "from mindspore import context\n",
        "\n",
        "parser = argparse.ArgumentParser(description='MindSpore LeNet Example')\n",
        "parser.add_argument('--device_target', type=str, default=\"CPU\", choices=['Ascend', 'GPU', 'CPU'])\n",
        "\n",
        "args = parser.parse_known_args()[0]\n",
        "context.set_context(mode=context.GRAPH_MODE, device_target=args.device_target)"
      ],
      "metadata": {
        "id": "xEmStyasTdIi"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import os\n",
        "# import requests\n",
        "\n",
        "# def download_dataset(dataset_url, path):\n",
        "#     filename = dataset_url.split(\"/\")[-1]\n",
        "#     save_path = os.path.join(path, filename)\n",
        "#     if os.path.exists(save_path):\n",
        "#         return\n",
        "#     if not os.path.exists(path):\n",
        "#         os.makedirs(path)\n",
        "#     res = requests.get(dataset_url, stream=True, verify=False)\n",
        "#     with open(save_path, \"wb\") as f:\n",
        "#         for chunk in res.iter_content(chunk_size=512):\n",
        "#             if chunk:\n",
        "#                 f.write(chunk)\n",
        "\n",
        "# train_path = \"datasets/MNIST_Data/train\"\n",
        "# test_path = \"datasets/MNIST_Data/test\"\n",
        "\n",
        "# download_dataset(\"https://mindspore-website.obs.myhuaweicloud.com/notebook/datasets/mnist/train-labels-idx1-ubyte\", train_path)\n",
        "# download_dataset(\"https://mindspore-website.obs.myhuaweicloud.com/notebook/datasets/mnist/train-images-idx3-ubyte\", train_path)\n",
        "# download_dataset(\"https://mindspore-website.obs.myhuaweicloud.com/notebook/datasets/mnist/t10k-labels-idx1-ubyte\", test_path)\n",
        "# download_dataset(\"https://mindspore-website.obs.myhuaweicloud.com/notebook/datasets/mnist/t10k-images-idx3-ubyte\", test_path)"
      ],
      "metadata": {
        "id": "SrN3ETaPW_Fk"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import mindspore.dataset as ds\n",
        "import mindspore.dataset.transforms.c_transforms as C\n",
        "import mindspore.dataset.vision.c_transforms as CV\n",
        "from mindspore.dataset.vision import Inter\n",
        "from mindspore import dtype as mstype"
      ],
      "metadata": {
        "id": "25RLGJXNaD9f"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_dataset(data_path, batch_size=32, repeat_size=1,\n",
        "                   num_parallel_workers=1):\n",
        "    # Define the dataset.\n",
        "    mnist_ds = ds.MnistDataset(data_path)\n",
        "    resize_height, resize_width = 32, 32\n",
        "    rescale = 1.0 / 255.0\n",
        "    shift = 0.0\n",
        "    rescale_nml = 1 / 0.3081\n",
        "    shift_nml = -1 * 0.1307 / 0.3081\n",
        "\n",
        "    # Define the mapping to be operated.\n",
        "    resize_op = CV.Resize((resize_height, resize_width), interpolation=Inter.LINEAR)\n",
        "    rescale_nml_op = CV.Rescale(rescale_nml, shift_nml)\n",
        "    rescale_op = CV.Rescale(rescale, shift)\n",
        "    hwc2chw_op = CV.HWC2CHW()\n",
        "    type_cast_op = C.TypeCast(mstype.int32)\n",
        "\n",
        "    # Use the map function to apply data operations to the dataset.\n",
        "    mnist_ds = mnist_ds.map(operations=type_cast_op, input_columns=\"label\", num_parallel_workers=num_parallel_workers)\n",
        "    mnist_ds = mnist_ds.map(operations=[resize_op, rescale_op, rescale_nml_op, hwc2chw_op], input_columns=\"image\", num_parallel_workers=num_parallel_workers)\n",
        "\n",
        "\n",
        "    # Perform shuffle, batch and repeat operations.\n",
        "    buffer_size = 10000\n",
        "    mnist_ds = mnist_ds.shuffle(buffer_size=buffer_size)\n",
        "    mnist_ds = mnist_ds.batch(batch_size, drop_remainder=True)\n",
        "    mnist_ds = mnist_ds.repeat(count=repeat_size)\n",
        "\n",
        "    return mnist_ds"
      ],
      "metadata": {
        "id": "_pNKvhjHaIXW"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import mindspore.nn as nn\n",
        "from mindspore.common.initializer import Normal\n",
        "from mindspore.ops import ImageSummary, TensorSummary\n",
        "\n",
        "class LeNet5(nn.Cell):\n",
        "    \"\"\"\n",
        "    Lenet network structure\n",
        "    \"\"\"\n",
        "    def __init__(self, num_class=10, num_channel=1):\n",
        "        super(LeNet5, self).__init__()\n",
        "        # Define the required operation.\n",
        "        self.conv1 = nn.Conv2d(num_channel, 6, 5, pad_mode='valid')\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5, pad_mode='valid')\n",
        "        self.fc1 = nn.Dense(16 * 5 * 5, 120, weight_init=Normal(0.02))\n",
        "        self.fc2 = nn.Dense(120, 84, weight_init=Normal(0.02))\n",
        "        self.fc3 = nn.Dense(84, num_class, weight_init=Normal(0.02))\n",
        "        self.relu = nn.ReLU()\n",
        "        self.max_pool2d = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.image_summary = ImageSummary()\n",
        "        self.tensor_summary = TensorSummary()\n",
        "\n",
        "    def construct(self, x):\n",
        "        # Use the defined operation to construct a forward network.\n",
        "        self.image_summary(\"image\", x)\n",
        "        x = self.conv1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.max_pool2d(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.max_pool2d(x)\n",
        "        x = self.flatten(x)\n",
        "        x = self.fc1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.fc2(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.fc3(x)\n",
        "        self.tensor_summary(\"tensor\", x)\n",
        "        return x\n",
        "\n",
        "# Instantiate the network.\n",
        "net = LeNet5()"
      ],
      "metadata": {
        "id": "AuBZuPGgaMGF"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the loss function.\n",
        "net_loss = nn.SoftmaxCrossEntropyWithLogits(sparse=True, reduction='mean')\n",
        "\n",
        "# Define the optimizer.\n",
        "net_opt = nn.Momentum(net.trainable_params(), learning_rate=0.01, momentum=0.9)"
      ],
      "metadata": {
        "id": "5jBl6uBcaT1-"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from mindspore.train.callback import ModelCheckpoint, CheckpointConfig\n",
        "# Set model saving parameters.\n",
        "config_ck = CheckpointConfig(save_checkpoint_steps=1875, keep_checkpoint_max=10)\n",
        "# Use model saving parameters.\n",
        "ckpoint = ModelCheckpoint(prefix=\"checkpoint_lenet\", config=config_ck)"
      ],
      "metadata": {
        "id": "aMeMlrJEaaaQ"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the library required for model training.\n",
        "from mindspore.nn import Accuracy\n",
        "from mindspore.train.callback import LossMonitor\n",
        "from mindspore import Model"
      ],
      "metadata": {
        "id": "maygQebEagFj"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from  mindspore.train.callback import SummaryCollector\n",
        "def train_net(model, epoch_size, data_path, repeat_size, ckpoint_cb, sink_mode):\n",
        "    \"\"\"Define a training method.\"\"\"\n",
        "    # Load the training dataset.\n",
        "    ds_train = create_dataset(os.path.join(data_path, \"train\"), 32, repeat_size)\n",
        "    summary_collector = SummaryCollector(summary_dir=\"./summary_dir\", collect_freq=1)\n",
        "    model.train(epoch_size, ds_train, callbacks=[ckpoint_cb, LossMonitor(125), summary_collector], dataset_sink_mode=sink_mode)"
      ],
      "metadata": {
        "id": "2ZTjNgy-alth"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test_net(model, data_path):\n",
        "    \"\"\"Define a validation method.\"\"\"\n",
        "    ds_eval = create_dataset(os.path.join(data_path, \"test\"))\n",
        "    acc = model.eval(ds_eval, dataset_sink_mode=False)\n",
        "    print(\"{}\".format(acc))"
      ],
      "metadata": {
        "id": "ZIwP7MEUarkp"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from mindspore.profiler import Profiler\n",
        "profiler = Profiler(output_path = './summary_dir/profiler_data')\n",
        "\n",
        "train_epoch = 1\n",
        "mnist_path = \"./datasets/MNIST_Data\"\n",
        "dataset_size = 1\n",
        "model = Model(net, net_loss, net_opt, metrics={\"Accuracy\": Accuracy()})\n",
        "train_net(model, train_epoch, mnist_path, dataset_size, ckpoint, False)\n",
        "profiler.analyse()\n",
        "test_net(model, mnist_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T_Laubm9auHe",
        "outputId": "4588045c-85d5-453b-f55d-bb0aea1cea05"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[WARNING] ME(2436:139745616672640,MainProcess):2022-05-02-13:22:07.992.712 [mindspore/profiler/profiling.py:1088] For 'Profiler', fail to get RANK_ID from environment, use 0 instead.\n",
            "[WARNING] ME(2436:139745616672640,MainProcess):2022-05-02-13:22:07.999.042 [mindspore/profiler/profiling.py:1120] The target dir already exists. There may be some old profiling data, and they will be rewritten in the end.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 1 step: 125, loss is 2.3008828163146973\n",
            "epoch: 1 step: 250, loss is 2.3078672885894775\n",
            "epoch: 1 step: 375, loss is 2.29052996635437\n",
            "epoch: 1 step: 500, loss is 2.309715986251831\n",
            "epoch: 1 step: 625, loss is 2.3020195960998535\n",
            "epoch: 1 step: 750, loss is 2.2945330142974854\n",
            "epoch: 1 step: 875, loss is 2.30362868309021\n",
            "epoch: 1 step: 1000, loss is 1.013251781463623\n",
            "epoch: 1 step: 1125, loss is 0.49862974882125854\n",
            "epoch: 1 step: 1250, loss is 0.17927120625972748\n",
            "epoch: 1 step: 1375, loss is 0.09902582317590714\n",
            "epoch: 1 step: 1500, loss is 0.019941840320825577\n",
            "epoch: 1 step: 1625, loss is 0.19769784808158875\n",
            "epoch: 1 step: 1750, loss is 0.06956019252538681\n",
            "epoch: 1 step: 1875, loss is 0.22431671619415283\n",
            "{'Accuracy': 0.9651442307692307}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from mindspore import load_checkpoint, load_param_into_net\n",
        "# Load the saved model for testing.\n",
        "param_dict = load_checkpoint(\"checkpoint_lenet-1_1875.ckpt\")\n",
        "# Load parameters to the network.\n",
        "load_param_into_net(net, param_dict)"
      ],
      "metadata": {
        "id": "hLTPc8NhbaW7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "85c907e4-872c-4fcb-99bf-691fc3d7ff16"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from mindspore import Tensor\n",
        "\n",
        "# Define a test dataset. If batch_size is set to 1, an image is obtained.\n",
        "ds_test = create_dataset(os.path.join(mnist_path, \"test\"), batch_size=1).create_dict_iterator()\n",
        "data = next(ds_test)\n",
        "\n",
        "# `images` indicates the test image, and `labels` indicates the actual classification of the test image.\n",
        "images = data[\"image\"].asnumpy()\n",
        "labels = data[\"label\"].asnumpy()\n",
        "\n",
        "# Use the model.predict function to predict the classification of the image.\n",
        "output = model.predict(Tensor(data['image']))\n",
        "predicted = np.argmax(output.asnumpy(), axis=1)\n",
        "\n",
        "# Output the predicted classification and the actual classification.\n",
        "print(f'Predicted: \"{predicted[0]}\", Actual: \"{labels[0]}\"')"
      ],
      "metadata": {
        "id": "kKp1M5--bfSv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2e46a350-259d-4bc6-c923-0f30a1f1d088"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted: \"0\", Actual: \"0\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !mindinsight start --summary-base-dir ./summary_dir --port 8081"
      ],
      "metadata": {
        "id": "-sHiyub0sw1R"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !mindinsight stop --port 8081"
      ],
      "metadata": {
        "id": "CV31C2rstZA_"
      },
      "execution_count": 17,
      "outputs": []
    }
  ]
}